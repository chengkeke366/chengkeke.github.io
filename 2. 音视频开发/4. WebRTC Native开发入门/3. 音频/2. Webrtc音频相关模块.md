WebRtcVoiceEngine

* AudioEncoderFactory
* AudioDecoderFactory
* AudioDeviceModule  : adm 模块
* AudioMixer
* AudioProcessing : apm模块
* AudioState



## 思考问题

* 问题1：webrtc何时创建adm模块？

  > 答案：在调用webrtc::CreatePeerConnectionFactory时进行adm的创建

* 问题2： voiceEngine的作用是什么？与adm有啥关系？

  > 答案：voice engine是音频处理引擎，可以进行adm管理，apm、amix处理。  adm是voice Engine中的一个成员指针。

* WebRtcVoiceMediaChannel 与 voiceEngine的关系？

  > webrtc通过WebRtcVoiceMediaChannel来调用voiceEngine来进行音频处理。 voiceEngine作为 WebRtcVoiceMediaChannel 的一个成员。

* CompositeMediaEngine 与 voiceEngine 、 videoEngine的关系？

  > CompositeMediaEngine  包含voiceEngine、voideEngine成员。其自身并不实现任何功能。

* WebRtcVideoChannel/WebRtcVoiceMediaChannel 、VoiceMediaChannel /VideoMediaChannel、MediaChannel、BaseChannel 之间的关系

  > WebRtcVoiceMediaChannel 与WebRtcVideoChannel 分别继承自VoiceMediaChannel 与VideoMediaChannel。
  >
  > VoiceMediaChannel 与VideoMediaChannel 都继承自MediaChannel。
  >
  > **其中BaseChannel是数据收发的入口：(以视频为例)**
  >
  > * 收数据  --->RtpDemuxer::OnRtpPacket ---> BaseChannel::OnRtpPacket --->WebRtcVideoChannel::OnPacketReceived
  > * 发数据    WebRtcVideoChannel::SendRtp --->MediaChannel::SendRtp-->BaseChannel::SendPacket--->SrtpTransport::SendRtpPacket--->RtpTransport::SendPacket--->DtlsTransport::SendPacket--->P2PTransportChannel::SendPacket--->ProxyConnection::Send--->UDPPort::SendTo--->AsyncUDPSocket::SendTo--->PhysicalSocket::SendTo

  ​	

## 一：WebRTC构造AMD模块

**如下为源码解析：**

我们使用webrtc时，第一步就是要创建PC工厂，有了PC工厂我们就可以用PC工厂创建PC及Track等对象。

PC工厂内完成许多资源的创建及音视频引擎的创建。我们可以指定三大线程、apm、adm、amix、编解码工厂等

```c++
  peer_connection_factory_ = webrtc::CreatePeerConnectionFactory(
      nullptr /* network_thread */, nullptr /* worker_thread */,
      signaling_thread_.get(), nullptr /* default_adm */,
      webrtc::CreateBuiltinAudioEncoderFactory(),
      webrtc::CreateBuiltinAudioDecoderFactory(),
      webrtc::CreateBuiltinVideoEncoderFactory(),
      webrtc::CreateBuiltinVideoDecoderFactory(), nullptr /* audio_mixer */,
      nullptr /* audio_processing */);
```

进入函数

```c++
rtc::scoped_refptr<PeerConnectionFactoryInterface> CreatePeerConnectionFactory(
    rtc::Thread* network_thread,
    rtc::Thread* worker_thread,
    rtc::Thread* signaling_thread,
    rtc::scoped_refptr<AudioDeviceModule> default_adm,
    rtc::scoped_refptr<AudioEncoderFactory> audio_encoder_factory,
    rtc::scoped_refptr<AudioDecoderFactory> audio_decoder_factory,
    std::unique_ptr<VideoEncoderFactory> video_encoder_factory,
    std::unique_ptr<VideoDecoderFactory> video_decoder_factory,
    rtc::scoped_refptr<AudioMixer> audio_mixer,
    rtc::scoped_refptr<AudioProcessing> audio_processing,
    AudioFrameProcessor* audio_frame_processor) {
  PeerConnectionFactoryDependencies dependencies;
  dependencies.network_thread = network_thread;
  dependencies.worker_thread = worker_thread;
  dependencies.signaling_thread = signaling_thread;
  dependencies.task_queue_factory = CreateDefaultTaskQueueFactory();
  dependencies.call_factory = CreateCallFactory();
  dependencies.event_log_factory = std::make_unique<RtcEventLogFactory>(
      dependencies.task_queue_factory.get());
  dependencies.trials = std::make_unique<webrtc::FieldTrialBasedConfig>();

  cricket::MediaEngineDependencies media_dependencies;
  media_dependencies.task_queue_factory = dependencies.task_queue_factory.get();
   //外部传入的AMD,可能为nullptr，只做赋值操作
  media_dependencies.adm = std::move(default_adm);
  media_dependencies.audio_encoder_factory = std::move(audio_encoder_factory);
  media_dependencies.audio_decoder_factory = std::move(audio_decoder_factory);
  media_dependencies.audio_frame_processor = audio_frame_processor;
  if (audio_processing) {
    media_dependencies.audio_processing = std::move(audio_processing);
  } else {
      //创建默认的APM
    media_dependencies.audio_processing = AudioProcessingBuilder().Create();
  }
  media_dependencies.audio_mixer = std::move(audio_mixer);
  media_dependencies.video_encoder_factory = std::move(video_encoder_factory);
  media_dependencies.video_decoder_factory = std::move(video_decoder_factory);
  media_dependencies.trials = dependencies.trials.get();
  //创建Rtc音视频引擎。
  dependencies.media_engine =
      cricket::CreateMediaEngine(std::move(media_dependencies));
    
  //创建PeerConnectionFactoryInterface
  return CreateModularPeerConnectionFactory(std::move(dependencies));
}
```



```c++
std::unique_ptr<MediaEngineInterface> CreateMediaEngine(
    MediaEngineDependencies dependencies) {
  // TODO(sprang): Make populating `dependencies.trials` mandatory and remove
  // these fallbacks.
  std::unique_ptr<webrtc::WebRtcKeyValueConfig> fallback_trials(
      dependencies.trials ? nullptr : new webrtc::FieldTrialBasedConfig());
  const webrtc::WebRtcKeyValueConfig& trials =
      dependencies.trials ? *dependencies.trials : *fallback_trials;
    //创建音频引擎
  auto audio_engine = std::make_unique<WebRtcVoiceEngine>(
      dependencies.task_queue_factory, std::move(dependencies.adm),
      std::move(dependencies.audio_encoder_factory),
      std::move(dependencies.audio_decoder_factory),
      std::move(dependencies.audio_mixer),
      std::move(dependencies.audio_processing),
      dependencies.audio_frame_processor, trials);
#ifdef HAVE_WEBRTC_VIDEO
    //创建视频引擎
  auto video_engine = std::make_unique<WebRtcVideoEngine>(
      std::move(dependencies.video_encoder_factory),
      std::move(dependencies.video_decoder_factory), trials);
#else
  auto video_engine = std::make_unique<NullWebRtcVideoEngine>();
#endif
    //创建CompositeMediaEngine引擎
  return std::make_unique<CompositeMediaEngine>(std::move(fallback_trials),
                                                std::move(audio_engine),
                                                std::move(video_engine));
}
```



音频引擎 `WebRtcVoiceEngine`构造主要拿到外部传入的任务队列工厂、adm、 encode 编解码工厂、apm、amix等模块的指针。

```c++
WebRtcVoiceEngine::WebRtcVoiceEngine(
    webrtc::TaskQueueFactory* task_queue_factory,
    webrtc::AudioDeviceModule* adm,
    const rtc::scoped_refptr<webrtc::AudioEncoderFactory>& encoder_factory,
    const rtc::scoped_refptr<webrtc::AudioDecoderFactory>& decoder_factory,
    rtc::scoped_refptr<webrtc::AudioMixer> audio_mixer,
    rtc::scoped_refptr<webrtc::AudioProcessing> audio_processing,
    webrtc::AudioFrameProcessor* audio_frame_processor,
    const webrtc::WebRtcKeyValueConfig& trials)
    : task_queue_factory_(task_queue_factory),
      adm_(adm),// 为CreatePeerConnectionFactory传入的amd值，可能为null
      encoder_factory_(encoder_factory),
      decoder_factory_(decoder_factory),
      audio_mixer_(audio_mixer),
      apm_(audio_processing),//肯定不为null，为CreatePeerConnectionFactory中完成了实例化
      audio_frame_processor_(audio_frame_processor),
      audio_red_for_opus_enabled_(
          !IsDisabled(trials, "WebRTC-Audio-Red-For-Opus")),
      minimized_remsampling_on_mobile_trial_enabled_(
          IsEnabled(trials, "WebRTC-Audio-MinimizeResamplingOnMobile")) {
  // This may be called from any thread, so detach thread checkers.
  worker_thread_checker_.Detach();
  signal_thread_checker_.Detach();
  RTC_LOG(LS_INFO) << "WebRtcVoiceEngine::WebRtcVoiceEngine";
  RTC_DCHECK(decoder_factory);
  RTC_DCHECK(encoder_factory);
  // The rest of our initialization will happen in Init.
}
```



  `CreateModularPeerConnectionFactory` 函数中执行WebRtcVoiceEngine::init 操作。

```c++
rtc::scoped_refptr<PeerConnectionFactoryInterface>
CreateModularPeerConnectionFactory(
    PeerConnectionFactoryDependencies dependencies) {
  // The PeerConnectionFactory must be created on the signaling thread.
  if (dependencies.signaling_thread &&
      !dependencies.signaling_thread->IsCurrent()) {
    return dependencies.signaling_thread
        ->Invoke<rtc::scoped_refptr<PeerConnectionFactoryInterface>>(
            RTC_FROM_HERE, [&dependencies] {
              return CreateModularPeerConnectionFactory(
                  std::move(dependencies));
            });
  }
  //创建PeerConnectionFactory
  auto pc_factory = PeerConnectionFactory::Create(std::move(dependencies));
  if (!pc_factory) {
    return nullptr;
  }
  // Verify that the invocation and the initialization ended up agreeing on the
  // thread.
  RTC_DCHECK_RUN_ON(pc_factory->signaling_thread());
  return PeerConnectionFactoryProxy::Create(
      pc_factory->signaling_thread(), pc_factory->worker_thread(), pc_factory);
}
```

PC工厂上下文创建

```c++
// Static
rtc::scoped_refptr<PeerConnectionFactory> PeerConnectionFactory::Create(
    PeerConnectionFactoryDependencies dependencies) {
   //PeerConnectionFactory上下文创建
  auto context = ConnectionContext::Create(&dependencies);
  if (!context) {
    return nullptr;
  }
    //调用 PeerConnectionFactory::PeerConnectionFactory 完成创建
  return rtc::make_ref_counted<PeerConnectionFactory>(context, &dependencies);
}
```



上下文创建完成了开启了三大线程，网络模块初始化， channelManager的创建

```c++
ConnectionContext::ConnectionContext(
    PeerConnectionFactoryDependencies* dependencies)
    //启动线程
    : network_thread_(MaybeStartThread(dependencies->network_thread,
                                       "pc_network_thread",
                                       true,
                                       owned_network_thread_)),
      worker_thread_(MaybeStartThread(dependencies->worker_thread,
                                      "pc_worker_thread",
                                      false,
                                      owned_worker_thread_)),
      signaling_thread_(MaybeWrapThread(dependencies->signaling_thread,
                                        wraps_current_thread_)),
      network_monitor_factory_(
          std::move(dependencies->network_monitor_factory)),
      call_factory_(std::move(dependencies->call_factory)),
      sctp_factory_(
          MaybeCreateSctpFactory(std::move(dependencies->sctp_factory),
                                 network_thread())),
      trials_(dependencies->trials
                  ? std::move(dependencies->trials)
                  : std::make_unique<FieldTrialBasedConfig>()) {
  signaling_thread_->AllowInvokesToThread(worker_thread_);
  signaling_thread_->AllowInvokesToThread(network_thread_);
  worker_thread_->AllowInvokesToThread(network_thread_);
  if (network_thread_->IsCurrent()) {
    // TODO(https://crbug.com/webrtc/12802) switch to DisallowAllInvokes
    network_thread_->AllowInvokesToThread(network_thread_);
  } else {
    network_thread_->PostTask(ToQueuedTask([thread = network_thread_] {
      thread->DisallowBlockingCalls();
      // TODO(https://crbug.com/webrtc/12802) switch to DisallowAllInvokes
      thread->AllowInvokesToThread(thread);
    }));
  }

  RTC_DCHECK_RUN_ON(signaling_thread_);
  rtc::InitRandom(rtc::Time32());

  // If network_monitor_factory_ is non-null, it will be used to create a
  // network monitor while on the network thread.
  default_network_manager_ = std::make_unique<rtc::BasicNetworkManager>(
      network_monitor_factory_.get(), network_thread()->socketserver());

  // TODO(bugs.webrtc.org/13145): Either require that a PacketSocketFactory
  // always is injected (with no need to construct this default factory), or get
  // the appropriate underlying SocketFactory without going through the
  // rtc::Thread::socketserver() accessor.
  default_socket_factory_ = std::make_unique<rtc::BasicPacketSocketFactory>(
      network_thread()->socketserver());

  //通道管理，Create中初始化了Media Engine voice的音频模块
  worker_thread_->Invoke<void>(RTC_FROM_HERE, [&]() {
    channel_manager_ = cricket::ChannelManager::Create(
        std::move(dependencies->media_engine),
        /*enable_rtx=*/true, worker_thread(), network_thread());
  });

  // Set warning levels on the threads, to give warnings when response
  // may be slower than is expected of the thread.
  // Since some of the threads may be the same, start with the least
  // restrictive limits and end with the least permissive ones.
  // This will give warnings for all cases.
  signaling_thread_->SetDispatchWarningMs(100);
  worker_thread_->SetDispatchWarningMs(30);
  network_thread_->SetDispatchWarningMs(10);
}
```

ChannelManager 的创建完成了音频引擎的初始化

```c++
// static
std::unique_ptr<ChannelManager> ChannelManager::Create(
    std::unique_ptr<MediaEngineInterface> media_engine,
    bool enable_rtx,
    rtc::Thread* worker_thread,
    rtc::Thread* network_thread) {
  RTC_DCHECK_RUN_ON(worker_thread);
  RTC_DCHECK(network_thread);
  RTC_DCHECK(worker_thread);

    //音频模块初始化
  if (media_engine)
    media_engine->Init();

  return absl::WrapUnique(new ChannelManager(
      std::move(media_engine), enable_rtx, worker_thread, network_thread));
}
```

WebRtcVoiceEngine::Init其中adm、apm、amix、创建了Audio_state_成员。注册了Adm模块音频数据回调对象` adm()->RegisterAudioCallback(audio_state()->audio_transport());`。 剩余对3A ,jitter buffer选项进行了初始化。

```c++
void WebRtcVoiceEngine::Init() {
  RTC_DCHECK_RUN_ON(&worker_thread_checker_);
  RTC_LOG(LS_INFO) << "WebRtcVoiceEngine::Init";

  // TaskQueue expects to be created/destroyed on the same thread.
  low_priority_worker_queue_.reset(
      new rtc::TaskQueue(task_queue_factory_->CreateTaskQueue(
          "rtc-low-prio", webrtc::TaskQueueFactory::Priority::LOW)));

  // Load our audio codec lists.
  RTC_LOG(LS_VERBOSE) << "Supported send codecs in order of preference:";
  send_codecs_ = CollectCodecs(encoder_factory_->GetSupportedEncoders());
  for (const AudioCodec& codec : send_codecs_) {
    RTC_LOG(LS_VERBOSE) << ToString(codec);
  }

  RTC_LOG(LS_VERBOSE) << "Supported recv codecs in order of preference:";
  recv_codecs_ = CollectCodecs(decoder_factory_->GetSupportedDecoders());
  for (const AudioCodec& codec : recv_codecs_) {
    RTC_LOG(LS_VERBOSE) << ToString(codec);
  }

#if defined(WEBRTC_INCLUDE_INTERNAL_AUDIO_DEVICE)
  // No ADM supplied? Create a default one.
  if (!adm_) {
      //adm为null，则创建默认的adm
    adm_ = webrtc::AudioDeviceModule::Create(
        webrtc::AudioDeviceModule::kPlatformDefaultAudio, task_queue_factory_);
  }
#endif  // WEBRTC_INCLUDE_INTERNAL_AUDIO_DEVICE
  RTC_CHECK(adm());
  webrtc::adm_helpers::Init(adm());

  // Set up AudioState.
  {
     //构造一个 AudioState 对象赋值给成员audio_state_
    webrtc::AudioState::Config config;
    if (audio_mixer_) {
      config.audio_mixer = audio_mixer_;
    } else {
        //混音器
      config.audio_mixer = webrtc::AudioMixerImpl::Create();
    }
    config.audio_processing = apm_;
    config.audio_device_module = adm_;
    if (audio_frame_processor_)
      config.async_audio_processing_factory =
          rtc::make_ref_counted<webrtc::AsyncAudioProcessing::Factory>(
              *audio_frame_processor_, *task_queue_factory_);
      // 创建 Audio State
    audio_state_ = webrtc::AudioState::Create(config);
  }

  // Connect the ADM to our audio path. 音频数据的回调对象  audio_transport 是audio_state_的成员变量
  adm()->RegisterAudioCallback(audio_state()->audio_transport());

  // Set default engine options.
  {
    AudioOptions options;
    options.echo_cancellation = true;
    options.auto_gain_control = true;
#if defined(WEBRTC_IOS)
    // On iOS, VPIO provides built-in NS.
    options.noise_suppression = false;
    options.typing_detection = false;
#else
    options.noise_suppression = true;
    options.typing_detection = true;
#endif
    options.experimental_ns = false;
    options.highpass_filter = true;
    options.stereo_swapping = false;
    options.audio_jitter_buffer_max_packets = 200;
    options.audio_jitter_buffer_fast_accelerate = false;
    options.audio_jitter_buffer_min_delay_ms = 0;
    options.audio_jitter_buffer_enable_rtx_handling = false;
    options.experimental_agc = false;
    options.residual_echo_detector = true;
    bool error = ApplyOptions(options);
    RTC_DCHECK(error);
  }
  initialized_ = true;
}
```







1. webrtc如何调用adm来采集数据呢？