WebRtc M96中为实现混音提供了一个辅助类型`webrtc::FrameCombiner` 和一个格式转换函数`RemixAndResample`。



# 一：RTC 重采样实现

重采样函数如下：

* 首先根据AudioFrame中的声道数将src_data进行声道转换
* 在 `InitializeIfNeeded` 根据源与目标采样率大小是否一致，决定是否初始化 `PushResampler` 对象`resampler` 用来重采样
* 使用`resampler->Resample`进行重采样

```c++
void RemixAndResample(const int16_t* src_data,     //input
                      size_t samples_per_channel,  //input
                      size_t num_channels,		   //input
                      int sample_rate_hz,		   //input
                      PushResampler<int16_t>* resampler,
                      AudioFrame* dst_frame){
  const int16_t* audio_ptr = src_data;
  size_t audio_ptr_num_channels = num_channels;
  int16_t downmixed_audio[AudioFrame::kMaxDataSizeSamples];

  // Downmix before resampling. 如果源声道数大于目标声道数，那么向下重采样
  if (num_channels > dst_frame->num_channels_) {
    RTC_DCHECK(num_channels == 2 || num_channels == 4)
        << "num_channels: " << num_channels;
    RTC_DCHECK(dst_frame->num_channels_ == 1 || dst_frame->num_channels_ == 2)
        << "dst_frame->num_channels_: " << dst_frame->num_channels_;
	//完成多声道转单声道或4声道转双声道
    AudioFrameOperations::DownmixChannels(
        src_data, num_channels, samples_per_channel, dst_frame->num_channels_,
        downmixed_audio);
    audio_ptr = downmixed_audio;
    audio_ptr_num_channels = dst_frame->num_channels_;
  }

  if (resampler->InitializeIfNeeded(sample_rate_hz, dst_frame->sample_rate_hz_,
                                    audio_ptr_num_channels) == -1) {
    RTC_FATAL() << "InitializeIfNeeded failed: sample_rate_hz = "
                << sample_rate_hz << ", dst_frame->sample_rate_hz_ = "
                << dst_frame->sample_rate_hz_
                << ", audio_ptr_num_channels = " << audio_ptr_num_channels;
  }

  // TODO(yujo): for muted input frames, don't resample. Either 1) allow
  // resampler to return output length without doing the resample, so we know
  // how much to zero here; or 2) make resampler accept a hint that the input is
  // zeroed.
  const size_t src_length = samples_per_channel * audio_ptr_num_channels;
  int out_length =
      resampler->Resample(audio_ptr, src_length, dst_frame->mutable_data(),
                          AudioFrame::kMaxDataSizeSamples);
  if (out_length == -1) {
    RTC_FATAL() << "Resample failed: audio_ptr = " << audio_ptr
                << ", src_length = " << src_length
                << ", dst_frame->mutable_data() = "
                << dst_frame->mutable_data();
  }
  dst_frame->samples_per_channel_ = out_length / audio_ptr_num_channels;

  // Upmix after resampling.
  if (num_channels == 1 && dst_frame->num_channels_ == 2) {
    // The audio in dst_frame really is mono at this point; MonoToStereo will
    // set this back to stereo.
    dst_frame->num_channels_ = 1;
    AudioFrameOperations::UpmixChannels(2, dst_frame);
  }
}
```

### 1.1 声道转换

```c++
void AudioFrameOperations::DownmixChannels(const int16_t* src_audio,
                                           size_t src_channels,
                                           size_t samples_per_channel,
                                           size_t dst_channels,
                                           int16_t* dst_audio) {
    //源声道大于1， 目标声道为1
  if (src_channels > 1 && dst_channels == 1) {
    DownmixInterleavedToMono(src_audio, samples_per_channel, src_channels,
                             dst_audio);
    return;
  } else if (src_channels == 4 && dst_channels == 2) {//目标声道为2， 原声道为4
    QuadToStereo(src_audio, samples_per_channel, dst_audio);
    return;
  }

  RTC_NOTREACHED() << "src_channels: " << src_channels
                   << ", dst_channels: " << dst_channels;
}
```

* **多声道转单声道** 

  ```c++
  template <>
  void DownmixInterleavedToMono<int16_t>(const int16_t* interleaved,
                                         size_t num_frames,
                                         int num_channels,
                                         int16_t* deinterleaved) {
    DownmixInterleavedToMonoImpl<int16_t, int32_t>(interleaved, num_frames,
                                                   num_channels, deinterleaved);
  }
  ```

  T 为int16_t、Intermediate为int32_t。

  ```c++
  // Downmixes an interleaved multichannel signal to a single channel by averaging
  // all channels.
  
  /*看懂源码所需知识点：
  1. 一个音频Frame包含同一时间点所有声道的样本（Sample）
  2. int16_t *指针自增一次，向后偏移sizeof(int16_t)个字节
  3. 多声道转单声道：将每个声道的声音叠加，然后除以声道数
  */
  template <typename T, typename Intermediate>
  void DownmixInterleavedToMonoImpl(const T* interleaved,
                                    size_t num_frames,
                                    int num_channels,
                                    T* deinterleaved) {
    RTC_DCHECK_GT(num_channels, 0);
    RTC_DCHECK_GT(num_frames, 0);
    //计算所有帧的末尾位置
    const T* const end = interleaved + num_frames * num_channels;//计算所有样本数据末尾位置
  
    /*因为机器采集到的声音是Interleaved格式的，所以所有声道的数据是紧挨着的。
  	interleaved+num_channels interleaved指向frame开头， +number_channels可以计算出frame的末尾位置
    */
    while (interleaved < end) {
      const T* const frame_end = interleaved + num_channels;//计算每一帧的末尾位置
  
      Intermediate value = *interleaved++; //取第一个声道样本大小赋值给val，然后interleaved指向下一个声道
      while (interleaved < frame_end) {//遍历剩余声道的声音，叠加到value
        value += *interleaved++;
      }
  	//计算所有声道的平均音量
      *deinterleaved++ = value / num_channels; //最后将叠加的声音除以总声道数
    }
  }
  ```

* **4声道转双声道**

  ```c++
  /*
  思想：4声道转双声道， 将1-2声道叠加除以2， 将3-4声道样本叠加除以2（右移1相当于除以2）
  */
  
  void AudioFrameOperations::QuadToStereo(const int16_t* src_audio,
                                          size_t samples_per_channel,
                                          int16_t* dst_audio) {
    for (size_t i = 0; i < samples_per_channel; i++) {
      dst_audio[i * 2] =
          (static_cast<int32_t>(src_audio[4 * i]) + src_audio[4 * i + 1]) >> 1;
      dst_audio[i * 2 + 1] =
          (static_cast<int32_t>(src_audio[4 * i + 2]) + src_audio[4 * i + 3]) >>
          1;
    }
  }
  ```

### 1.2 重采样部分

	#### 1.2.1 根据采样率判断是否需要重采样

* 当src采样率与dst采样率一样、声道数一样（RemixAndResample函数参数resampler 如果每次都传临时变量，其成员channel_则都为0，即使采样率相同也会进行重采样。因此其一般为一个长函数生命周期的成员变量）
* 根据传入的声道数，为每个声道申请重采样器ChannelResampler对象。并初始化其成员std::vector source 大小，std::vector<int16_t> destination大小，真正的重采样功能在 PushSincResampler中。

```c++
template <typename T>
int PushResampler<T>::InitializeIfNeeded(int src_sample_rate_hz,
                                         int dst_sample_rate_hz,
                                         size_t num_channels) {
  CheckValidInitParams(src_sample_rate_hz, dst_sample_rate_hz, num_channels);

  if (src_sample_rate_hz == src_sample_rate_hz_ &&
      dst_sample_rate_hz == dst_sample_rate_hz_ &&
      num_channels == num_channels_) {
    // No-op if settings haven't changed.
    return 0;
  }

  if (src_sample_rate_hz <= 0 || dst_sample_rate_hz <= 0 || num_channels <= 0) {
    return -1;
  }

  //更新成员
  src_sample_rate_hz_ = src_sample_rate_hz;
  dst_sample_rate_hz_ = dst_sample_rate_hz;
  num_channels_ = num_channels;

  const size_t src_size_10ms_mono =
      static_cast<size_t>(src_sample_rate_hz / 100);
  const size_t dst_size_10ms_mono =
      static_cast<size_t>(dst_sample_rate_hz / 100);
  channel_resamplers_.clear();
    
  //每个通道申请一个ChannelResampler对象并初始化用于对每个声道进行重采样
  for (size_t i = 0; i < num_channels; ++i) {
    channel_resamplers_.push_back(ChannelResampler());
    auto channel_resampler = channel_resamplers_.rbegin();
    channel_resampler->resampler = std::make_unique<PushSincResampler>(
        src_size_10ms_mono, dst_size_10ms_mono);
    channel_resampler->source.resize(src_size_10ms_mono);
    channel_resampler->destination.resize(dst_size_10ms_mono);
  }

  channel_data_array_.resize(num_channels_);

  return 0;
}
```



### 1.2.2 重采样

```c++
template <typename T>
int PushResampler<T>::Resample(const T* src,
                               size_t src_length,
                               T* dst,
                               size_t dst_capacity) {
  CheckExpectedBufferSizes(src_length, dst_capacity, num_channels_,
                           src_sample_rate_hz_, dst_sample_rate_hz_);

  if (src_sample_rate_hz_ == dst_sample_rate_hz_) {
    // The old resampler provides this memcpy facility in the case of matching
    // sample rates, so reproduce it here for the sinc resampler.
    memcpy(dst, src, src_length * sizeof(T));
    return static_cast<int>(src_length);
  }

  const size_t src_length_mono = src_length / num_channels_;
  const size_t dst_capacity_mono = dst_capacity / num_channels_;

  for (size_t ch = 0; ch < num_channels_; ++ch) {
    channel_data_array_[ch] = channel_resamplers_[ch].source.data();
  }
	//读取每个声道的原始数据填入 channel_resamplers_[ch].source.data()
  Deinterleave(src, src_length_mono, num_channels_, channel_data_array_.data());

  size_t dst_length_mono = 0;
	//对每个声道进行重采样
  for (auto& resampler : channel_resamplers_) {
    dst_length_mono = resampler.resampler->Resample(
        resampler.source.data(), src_length_mono, resampler.destination.data(),
        dst_capacity_mono);
  }
  
  for (size_t ch = 0; ch < num_channels_; ++ch) {
    channel_data_array_[ch] = channel_resamplers_[ch].destination.data();
  }
 //交错将channel_resamplers_[ch].destination.data();数据填入 dst中
  Interleave(channel_data_array_.data(), dst_length_mono, num_channels_, dst);
  return static_cast<int>(dst_length_mono * num_channels_);
}
```

```c++
size_t PushSincResampler::Resample(const int16_t* source,
                                   size_t source_length,
                                   int16_t* destination,
                                   size_t destination_capacity) {
  if (!float_buffer_.get())
    float_buffer_.reset(new float[destination_frames_]);

  source_ptr_int_ = source;
  // Pass nullptr as the float source to have Run() read from the int16 source.
  Resample(nullptr, source_length, float_buffer_.get(), destination_frames_);
  FloatS16ToS16(float_buffer_.get(), destination_frames_, destination);
  source_ptr_int_ = nullptr;
  return destination_frames_;
}
```

```c++
size_t PushSincResampler::Resample(const float* source,
                                   size_t source_length,
                                   float* destination,
                                   size_t destination_capacity) {
  RTC_CHECK_EQ(source_length, resampler_->request_frames());
  RTC_CHECK_GE(destination_capacity, destination_frames_);
  // Cache the source pointer. Calling Resample() will immediately trigger
  // the Run() callback whereupon we provide the cached value.
  source_ptr_ = source;
  source_available_ = source_length;

  // On the first pass, we call Resample() twice. During the first call, we
  // provide dummy input and discard the output. This is done to prime the
  // SincResampler buffer with the correct delay (half the kernel size), thereby
  // ensuring that all later Resample() calls will only result in one input
  // request through Run().
  //
  // If this wasn't done, SincResampler would call Run() twice on the first
  // pass, and we'd have to introduce an entire `source_frames` of delay, rather
  // than the minimum half kernel.
  //
  // It works out that ChunkSize() is exactly the amount of output we need to
  // request in order to prime the buffer with a single Run() request for
  // `source_frames`.
  if (first_pass_)
    resampler_->Resample(resampler_->ChunkSize(), destination);

  resampler_->Resample(destination_frames_, destination);
  source_ptr_ = nullptr;
  return destination_frames_;
}
```

```c++
void SincResampler::Resample(size_t frames, float* destination) {
  size_t remaining_frames = frames;

  // Step (1) -- Prime the input buffer at the start of the input stream.
  if (!buffer_primed_ && remaining_frames) {
    read_cb_->Run(request_frames_, r0_);
    buffer_primed_ = true;
  }

  // Step (2) -- Resample!  const what we can outside of the loop for speed.  It
  // actually has an impact on ARM performance.  See inner loop comment below.
  const double current_io_ratio = io_sample_rate_ratio_;
  const float* const kernel_ptr = kernel_storage_.get();
  while (remaining_frames) {
    // `i` may be negative if the last Resample() call ended on an iteration
    // that put `virtual_source_idx_` over the limit.
    //
    // Note: The loop construct here can severely impact performance on ARM
    // or when built with clang.  See https://codereview.chromium.org/18566009/
    for (int i = static_cast<int>(
             ceil((block_size_ - virtual_source_idx_) / current_io_ratio));
         i > 0; --i) {
      RTC_DCHECK_LT(virtual_source_idx_, block_size_);

      // `virtual_source_idx_` lies in between two kernel offsets so figure out
      // what they are.
      const int source_idx = static_cast<int>(virtual_source_idx_);
      const double subsample_remainder = virtual_source_idx_ - source_idx;

      const double virtual_offset_idx =
          subsample_remainder * kKernelOffsetCount;
      const int offset_idx = static_cast<int>(virtual_offset_idx);

      // We'll compute "convolutions" for the two kernels which straddle
      // `virtual_source_idx_`.
      const float* const k1 = kernel_ptr + offset_idx * kKernelSize;
      const float* const k2 = k1 + kKernelSize;

      // Ensure `k1`, `k2` are 32-byte aligned for SIMD usage.  Should always be
      // true so long as kKernelSize is a multiple of 32.
      RTC_DCHECK_EQ(0, reinterpret_cast<uintptr_t>(k1) % 32);
      RTC_DCHECK_EQ(0, reinterpret_cast<uintptr_t>(k2) % 32);

      // Initialize input pointer based on quantized `virtual_source_idx_`.
      const float* const input_ptr = r1_ + source_idx;

      // Figure out how much to weight each kernel's "convolution".
      const double kernel_interpolation_factor =
          virtual_offset_idx - offset_idx;
      *destination++ =
          convolve_proc_(input_ptr, k1, k2, kernel_interpolation_factor);

      // Advance the virtual index.
      virtual_source_idx_ += current_io_ratio;

      if (!--remaining_frames)
        return;
    }

    // Wrap back around to the start.
    virtual_source_idx_ -= block_size_;

    // Step (3) -- Copy r3_, r4_ to r1_, r2_.
    // This wraps the last input frames back to the start of the buffer.
    memcpy(r1_, r3_, sizeof(*input_buffer_.get()) * kKernelSize);

    // Step (4) -- Reinitialize regions if necessary.
    if (r0_ == r2_)
      UpdateRegions(true);

    // Step (5) -- Refresh the buffer with more input.
    read_cb_->Run(request_frames_, r0_);
  }
}
```







## 二： 混音实现

* Webrtc::FrameCombiner

  * 用法

    ```C++
    std::vector<AudioFrame*> frame_list;
     frame_list.push_back(capture_audio_frame.get());
     frame_list.push_back(loopback_frame.get());
     frame_combiner_.Combine(frame_list, capture_audio_frame->num_channels_,
                             capture_audio_frame->sample_rate_hz_,
                             frame_list.size(), &mixed_capture_frame_);
    ```

  * 源码解析

    ```c++
    void FrameCombiner::Combine(rtc::ArrayView<AudioFrame* const> mix_list,
                                size_t number_of_channels,
                                int sample_rate,
                                size_t number_of_streams,
                                AudioFrame* audio_frame_for_mixing) {
      RTC_DCHECK(audio_frame_for_mixing);
    
      LogMixingStats(mix_list, sample_rate, number_of_streams);
    
      SetAudioFrameFields(mix_list, number_of_channels, sample_rate,
                          number_of_streams, audio_frame_for_mixing);
    
      const size_t samples_per_channel = static_cast<size_t>(
          (sample_rate * webrtc::AudioMixerImpl::kFrameDurationInMs) / 1000);
    
      for (const auto* frame : mix_list) {
        RTC_DCHECK_EQ(samples_per_channel, frame->samples_per_channel_);
        RTC_DCHECK_EQ(sample_rate, frame->sample_rate_hz_);
      }
    
      // The 'num_channels_' field of frames in 'mix_list' could be
      // different from 'number_of_channels'.
      for (auto* frame : mix_list) {
        RemixFrame(number_of_channels, frame);
      }
    
      if (number_of_streams <= 1) {
        MixFewFramesWithNoLimiter(mix_list, audio_frame_for_mixing);
        return;
      }
    
      MixToFloatFrame(mix_list, samples_per_channel, number_of_channels,
                      mixing_buffer_.get());
    
      const size_t output_number_of_channels =
          std::min(number_of_channels, kMaximumNumberOfChannels);
      const size_t output_samples_per_channel =
          std::min(samples_per_channel, kMaximumChannelSize);
    
      // Put float data in an AudioFrameView.
      std::array<float*, kMaximumNumberOfChannels> channel_pointers{};
      for (size_t i = 0; i < output_number_of_channels; ++i) {
        channel_pointers[i] = &(*mixing_buffer_.get())[i][0];
      }
      AudioFrameView<float> mixing_buffer_view(&channel_pointers[0],
                                               output_number_of_channels,
                                               output_samples_per_channel);
    
      if (use_limiter_) {
        RunLimiter(mixing_buffer_view, &limiter_);
      }
    
      InterleaveToAudioFrame(mixing_buffer_view, audio_frame_for_mixing);
    }
    ```

    

