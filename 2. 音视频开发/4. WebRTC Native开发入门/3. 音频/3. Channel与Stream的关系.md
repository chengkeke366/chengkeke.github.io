在[2. Webrtc音频模块如何工作的](./2. Webrtc音频模块如何工作的.md)我们知道了SDP中每个m seciton都是一个sdp content。 在RTC 内部会实例化一个BaseChannel，BaseChannel包含一个MediaChannel对象。

通过BaseChannel的`UpdateMediaSendRecvState_w`来控制音视频的采集和渲染，其中控制的实现：

```c++
void WebRtcVoiceMediaChannel::SetSend(bool send) {
  TRACE_EVENT0("webrtc", "WebRtcVoiceMediaChannel::SetSend");
  if (send_ == send) {
    return;
  }

  // Apply channel specific options, and initialize the ADM for recording (this
  // may take time on some platforms, e.g. Android).
  if (send) {
    engine()->ApplyOptions(options_);

    // InitRecording() may return an error if the ADM is already recording.
    if (!engine()->adm()->RecordingIsInitialized() &&
        !engine()->adm()->Recording()) {
      if (engine()->adm()->InitRecording() != 0) {
        RTC_LOG(LS_WARNING) << "Failed to initialize recording";
      }
    }
  }

  // Change the settings on each send channel.
  for (auto& kv : send_streams_) {
    kv.second->SetSend(send);
  }

  send_ = send;
}
```

可以看到 真正的控制是在 WebRtcAudioSendStream（WebRtcVideoChannel内部嵌套类）和WebRtcAudioReceiveStream（WebRtcVoiceMediaChannel的内部嵌套类）中完成的。



具体的音频的采集在AudioSendStream中控制的，

